"""
å®éªŒç»“æœåˆ†æå’Œå¯¹æ¯”è„šæœ¬
ç”Ÿæˆè®ºæ–‡æ‰€éœ€çš„å¯¹æ¯”è¡¨æ ¼å’Œå›¾è¡¨
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from ultralytics import YOLO

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False


def analyze_training_results():
    """åˆ†æè®­ç»ƒç»“æœå¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""

    print("=" * 70)
    print("ğŸ“Š YOLOv8n vs YOLOv8n+SimAM å®éªŒç»“æœåˆ†æ")
    print("=" * 70)

    # å®šä¹‰è·¯å¾„
    baseline_path = '../runs/baseline_yolov8n/weights/best.pt'
    simam_path = '../runs/train_simam/weights/best.pt'
    data_yaml = '../data_augmented/grape_augmented.yaml'
    output_dir = '../analysis_results'

    os.makedirs(output_dir, exist_ok=True)

    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    baseline = YOLO(baseline_path)
    simam = YOLO(simam_path)

    # åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯
    print("\nğŸ” åœ¨æµ‹è¯•é›†ä¸ŠéªŒè¯...")
    baseline_results = baseline.val(data=data_yaml, split='test')
    simam_results = simam.val(data=data_yaml, split='test')

    # æå–æŒ‡æ ‡
    metrics_data = {
        'æ¨¡å‹': ['YOLOv8n (Baseline)', 'YOLOv8n + SimAM'],
        'mAP@0.5': [
            baseline_results.box.map50,
            simam_results.box.map50
        ],
        'mAP@0.5:0.95': [
            baseline_results.box.map,
            simam_results.box.map
        ],
        'Precision': [
            baseline_results.box.mp,
            simam_results.box.mp
        ],
        'Recall': [
            baseline_results.box.mr,
            simam_results.box.mr
        ],
        'F1-Score': [
            2 * (baseline_results.box.mp * baseline_results.box.mr) /
            (baseline_results.box.mp + baseline_results.box.mr),
            2 * (simam_results.box.mp * simam_results.box.mr) /
            (simam_results.box.mp + simam_results.box.mr)
        ]
    }

    df = pd.DataFrame(metrics_data)

    # è®¡ç®—æå‡
    improvements = {}
    for col in ['mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall', 'F1-Score']:
        baseline_val = df.loc[0, col]
        simam_val = df.loc[1, col]
        improvement = ((simam_val - baseline_val) / baseline_val) * 100
        improvements[col] = improvement

    # æ‰“å°ç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“ˆ æ•´ä½“æ€§èƒ½å¯¹æ¯”")
    print("=" * 70)
    print(df.to_string(index=False))

    print("\n" + "=" * 70)
    print("ğŸ“Š æ€§èƒ½æå‡")
    print("=" * 70)
    for metric, improvement in improvements.items():
        symbol = "ğŸ“ˆ" if improvement > 0 else "ğŸ“‰"
        print(f"{symbol} {metric}: {improvement:+.2f}%")

    # ä¿å­˜CSV
    csv_path = os.path.join(output_dir, 'overall_comparison.csv')
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… æ•´ä½“å¯¹æ¯”å·²ä¿å­˜: {csv_path}")

    # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    generate_comparison_plots(df, improvements, output_dir)

    # å„ç±»åˆ«å¯¹æ¯”
    analyze_per_class_performance(baseline_results, simam_results, output_dir)

    # ç”ŸæˆLaTeXè¡¨æ ¼
    generate_latex_table(df, improvements, output_dir)

    print("\n" + "=" * 70)
    print("âœ… åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°:", output_dir)
    print("=" * 70)


def generate_comparison_plots(df, improvements, output_dir):
    """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""

    print("\nğŸ“Š ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")

    # 1. æ€§èƒ½å¯¹æ¯”æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(12, 6))

    metrics = ['mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall', 'F1-Score']
    x = range(len(metrics))
    width = 0.35

    baseline_vals = [df.loc[0, m] for m in metrics]
    simam_vals = [df.loc[1, m] for m in metrics]

    bars1 = ax.bar([i - width / 2 for i in x], baseline_vals, width,
                   label='YOLOv8n (Baseline)', color='skyblue')
    bars2 = ax.bar([i + width / 2 for i in x], simam_vals, width,
                   label='YOLOv8n + SimAM', color='orange')

    ax.set_xlabel('æŒ‡æ ‡', fontsize=12)
    ax.set_ylabel('æ•°å€¼', fontsize=12)
    ax.set_title('YOLOv8n vs YOLOv8n+SimAM æ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(metrics)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width() / 2., height,
                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_comparison.png'), dpi=300)
    print("  âœ… æ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜")
    plt.close()

    # 2. æå‡ç™¾åˆ†æ¯”å›¾
    fig, ax = plt.subplots(figsize=(10, 6))

    colors = ['green' if v > 0 else 'red' for v in improvements.values()]
    bars = ax.barh(list(improvements.keys()), list(improvements.values()), color=colors)

    ax.set_xlabel('æå‡ç™¾åˆ†æ¯” (%)', fontsize=12)
    ax.set_title('SimAMæ”¹è¿›å¸¦æ¥çš„æ€§èƒ½æå‡', fontsize=14, fontweight='bold')
    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)
    ax.grid(axis='x', alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, val) in enumerate(zip(bars, improvements.values())):
        ax.text(val, i, f' {val:+.2f}%', va='center', fontsize=10, fontweight='bold')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'improvement_percentage.png'), dpi=300)
    print("  âœ… æå‡ç™¾åˆ†æ¯”å›¾å·²ä¿å­˜")
    plt.close()


def analyze_per_class_performance(baseline_results, simam_results, output_dir):
    """å„ç±»åˆ«æ€§èƒ½åˆ†æ"""

    print("\nğŸ“Š åˆ†æå„ç±»åˆ«æ€§èƒ½...")

    # ç±»åˆ«åç§°
    class_names = ['black_rot', 'blight', 'black_measles', 'Healthy']

    # æå–å„ç±»åˆ«çš„mAP@0.5
    baseline_maps = baseline_results.box.maps  # å„ç±»åˆ«mAP
    simam_maps = simam_results.box.maps

    # åˆ›å»ºDataFrame
    per_class_data = {
        'ç±»åˆ«': class_names,
        'Baseline mAP@0.5': baseline_maps.tolist(),
        'SimAM mAP@0.5': simam_maps.tolist()
    }

    df_class = pd.DataFrame(per_class_data)
    df_class['æå‡ (%)'] = ((df_class['SimAM mAP@0.5'] - df_class['Baseline mAP@0.5']) /
                            df_class['Baseline mAP@0.5'] * 100)

    print("\n" + "=" * 70)
    print("ğŸ“Š å„ç±»åˆ«æ€§èƒ½å¯¹æ¯”")
    print("=" * 70)
    print(df_class.to_string(index=False))

    # ä¿å­˜CSV
    csv_path = os.path.join(output_dir, 'per_class_comparison.csv')
    df_class.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… å„ç±»åˆ«å¯¹æ¯”å·²ä¿å­˜: {csv_path}")

    # ç”Ÿæˆå„ç±»åˆ«å¯¹æ¯”å›¾
    fig, ax = plt.subplots(figsize=(10, 6))

    x = range(len(class_names))
    width = 0.35

    bars1 = ax.bar([i - width / 2 for i in x], df_class['Baseline mAP@0.5'], width,
                   label='Baseline', color='skyblue')
    bars2 = ax.bar([i + width / 2 for i in x], df_class['SimAM mAP@0.5'], width,
                   label='SimAM', color='orange')

    ax.set_xlabel('ç±»åˆ«', fontsize=12)
    ax.set_ylabel('mAP@0.5', fontsize=12)
    ax.set_title('å„ç±»åˆ«æ£€æµ‹æ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(class_names)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    # æ·»åŠ æå‡ç™¾åˆ†æ¯”æ ‡ç­¾
    for i, improvement in enumerate(df_class['æå‡ (%)']):
        y_pos = max(df_class.loc[i, 'Baseline mAP@0.5'],
                    df_class.loc[i, 'SimAM mAP@0.5']) + 0.02
        color = 'green' if improvement > 0 else 'red'
        ax.text(i, y_pos, f'{improvement:+.1f}%', ha='center',
                fontsize=10, fontweight='bold', color=color)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'per_class_comparison.png'), dpi=300)
    print("  âœ… å„ç±»åˆ«å¯¹æ¯”å›¾å·²ä¿å­˜")
    plt.close()


def generate_latex_table(df, improvements, output_dir):
    """ç”ŸæˆLaTeXæ ¼å¼è¡¨æ ¼ï¼ˆç”¨äºè®ºæ–‡ï¼‰"""

    print("\nğŸ“ ç”ŸæˆLaTeXè¡¨æ ¼...")

    latex_content = r"""\begin{table}[htbp]
\centering
\caption{YOLOv8nä¸YOLOv8n+SimAMæ€§èƒ½å¯¹æ¯”}
\label{tab:performance_comparison}
\begin{tabular}{lcccccc}
\toprule
\textbf{æ¨¡å‹} & \textbf{mAP@0.5} & \textbf{mAP@0.5:0.95} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{å‚æ•°é‡} \\
\midrule
"""

    for idx, row in df.iterrows():
        model = row['æ¨¡å‹']
        latex_content += f"{model} & "
        latex_content += f"{row['mAP@0.5']:.4f} & "
        latex_content += f"{row['mAP@0.5:0.95']:.4f} & "
        latex_content += f"{row['Precision']:.4f} & "
        latex_content += f"{row['Recall']:.4f} & "
        latex_content += f"{row['F1-Score']:.4f} & "
        latex_content += "3.0M \\\\\n"

    latex_content += r"""\midrule
\textbf{æå‡} & """

    latex_content += f"\\textbf{{{improvements['mAP@0.5']:+.2f}\%}} & "
    latex_content += f"\\textbf{{{improvements['mAP@0.5:0.95']:+.2f}\%}} & "
    latex_content += f"{improvements['Precision']:+.2f}\% & "
    latex_content += f"\\textbf{{{improvements['Recall']:+.2f}\%}} & "
    latex_content += f"{improvements['F1-Score']:+.2f}\% & "
    latex_content += "0 \\\\\n"

    latex_content += r"""\bottomrule
\end{tabular}
\end{table}
"""

    # ä¿å­˜LaTeXä»£ç 
    latex_path = os.path.join(output_dir, 'performance_table.tex')
    with open(latex_path, 'w', encoding='utf-8') as f:
        f.write(latex_content)

    print(f"  âœ… LaTeXè¡¨æ ¼å·²ä¿å­˜: {latex_path}")


if __name__ == "__main__":
    analyze_training_results()